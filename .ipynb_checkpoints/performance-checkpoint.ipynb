{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparision between FastAssert and the OpenAI API\n",
    "\n",
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: openai in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from requests) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /opt/conda/envs/notebookenv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup the OpenAI client\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def openai_constrained_generation(prompt: str, json_schema, model_name=\"gpt-3.5-turbo\"):\n",
    "\n",
    "    tools = [\n",
    "      {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "          \"name\": \"get_current_weather\",\n",
    "          \"description\": \"Get the current weather in a given location\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "              },\n",
    "              \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"],\n",
    "          },\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n",
    "    completion = client.chat.completions.create(\n",
    "      model=model_name,\n",
    "      messages=messages,\n",
    "      tools=tools,\n",
    "      tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\"}}\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.tool_calls[0].function.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"location\": \"Boston, MA\",\\n  \"unit\": \"celsius\"\\n}'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_constrained_generation(\"What's the weather like in Boston today?\", json_ob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect and test our FastAssert server\n",
    "Make sure the docker container is running and can serve requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is up and running!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "BASE_URL = \"http://127.0.0.1:8000\"\n",
    "\n",
    "# Ping the server\n",
    "ping_response = requests.get(f\"{BASE_URL}/health\")\n",
    "\n",
    "# Check if the request was successful\n",
    "if ping_response.status_code == 200:\n",
    "    print(\"Server is up and running!\")\n",
    "else:\n",
    "    raise ValueError(f\"Failed to reach the server, status code: {ping_response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test \n",
    "def constrained_generation(prompt: str, json_schema):\n",
    "\n",
    "    url = f\"{BASE_URL}/generate\"\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"schema\": json_schema\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    return response.text\n",
    "\n",
    "def time_constrained_generation(prompt: str, json_schema):\n",
    "\n",
    "    start_time = time.time()\n",
    "    constrained_generation(prompt, json_schema)\n",
    "    end_time = time.time()\n",
    "\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"text\":[\"What\\'s the weather like in Boston today?{\\\\n\\\\n\\\\\"location\\\\\": \\\\\"Boston, MA\\\\\",\\\\n\\\\n\\\\\"unit\"]}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_ob = {\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"location\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "    },\n",
    "    \"unit\": {\n",
    "      \"type\": \"string\",\n",
    "      \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "      \"description\": \"The temperature unit\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"location\", \"unit\"],\n",
    "  \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "constrained_generation(\"What's the weather like in Boston today?\", json_ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2996985912322998"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_constrained_generation(\"What's the weather like in Boston today?\", json_ob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's benchmark the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [{\n",
    "            \"location\": \"Paris\", \n",
    "            \"unit\": \"celsius\"\n",
    "          },\n",
    "          {\n",
    "            \"location\": \"Sydney\",\n",
    "            \"unit\": \"celsius\"\n",
    "          },\n",
    "          {\n",
    "            \"location\": \"Berlin\",\n",
    "            \"unit\": \"celsius\"\n",
    "          },\n",
    "          {\n",
    "            \"location\": \"Moscow\",\n",
    "            \"unit\": \"celsius\"\n",
    "          },\n",
    "          {\n",
    "            \"location\": \"Rio de Janeiro\",\n",
    "            \"unit\": \"celsius\"\n",
    "          },\n",
    "          {\n",
    "            \"location\": \"Toronto\",\n",
    "            \"unit\": \"fahrenheit\"\n",
    "          },\n",
    "          {\n",
    "            \"location\": \"Mumbai\",\n",
    "            \"unit\": \"celsius\"\n",
    "          },\n",
    "          {\n",
    "            \"location\": \"New York, NY\",\n",
    "            \"unit\": \"fahrenheit\"\n",
    "          },\n",
    "          {\n",
    "            \"location\": \"London\",\n",
    "            \"unit\": \"celsius\"\n",
    "          },\n",
    "          {\n",
    "            \"location\": \"Tokyo\",\n",
    "            \"unit\": \"celsius\"\n",
    "          }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_gpt3_5_times = []\n",
    "openai_gpt4_times = []\n",
    "fastassert_times = []\n",
    "\n",
    "for row in inputs:\n",
    "    # Time OpenAI gpt-3.5-turbo\n",
    "    start_time = time.time()\n",
    "    answer = openai_constrained_generation(f\"What's the weather like in {row.get('location')} today?\", json_ob)\n",
    "    end_time = time.time()\n",
    "    openai_gpt3_5_times.append(end_time - start_time)\n",
    "\n",
    "    # Time OpenAI gpt-4\n",
    "    start_time = time.time()\n",
    "    answer = openai_constrained_generation(f\"What's the weather like in {row.get('location')} today?\", json_ob, model_name=\"gpt-4\")\n",
    "    end_time = time.time()\n",
    "    openai_gpt4_times.append(end_time - start_time)\n",
    "\n",
    "    # Time FastAssert\n",
    "    start_time = time.time()\n",
    "    answer = constrained_generation(f\"What's the weather like in {row.get('location')} today?\", json_ob)\n",
    "    end_time = time.time()\n",
    "    fastassert_times.append(end_time - start_time)\n",
    "\n",
    "# Calculate the means and standard deviations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI GPT-3.5 Mean: 0.9235001802444458 s, Standard Deviation: 0.3361904433780215\n",
      "OpenAI GPT-4 Mean: 1.4428787231445312 s, Standard Deviation: 0.37582730624512495\n",
      "FastAssert Mean: 0.3033578395843506 s, Standard Deviation: 0.005584525695486718\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "# Assuming inputs are defined and the above loop code has been executed\n",
    "\n",
    "# Calculate mean and standard deviation for OpenAI GPT-3.5 times\n",
    "mean_gpt3_5 = statistics.mean(openai_gpt3_5_times)\n",
    "std_dev_gpt3_5 = statistics.stdev(openai_gpt3_5_times)\n",
    "\n",
    "# Calculate mean and standard deviation for OpenAI GPT-4 times\n",
    "mean_gpt4 = statistics.mean(openai_gpt4_times)\n",
    "std_dev_gpt4 = statistics.stdev(openai_gpt4_times)\n",
    "\n",
    "# Calculate mean and standard deviation for FastAssert times\n",
    "mean_fastassert = statistics.mean(fastassert_times)\n",
    "std_dev_fastassert = statistics.stdev(fastassert_times)\n",
    "\n",
    "# Print the results\n",
    "print(f\"OpenAI GPT-3.5 Mean: {mean_gpt3_5} s, Standard Deviation: {std_dev_gpt3_5}\")\n",
    "print(f\"OpenAI GPT-4 Mean: {mean_gpt4} s, Standard Deviation: {std_dev_gpt4}\")\n",
    "print(f\"FastAssert Mean: {mean_fastassert} s, Standard Deviation: {std_dev_fastassert}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (notebookenv)",
   "language": "python",
   "name": "notebookenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
